{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349fb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import pickle  # For saving and loading intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e884bc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\hirom\\\\NLP\\\\LLM\\\\fcc-gpt-course',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\python39.zip',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\DLLs',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3',\n",
      " '',\n",
      " 'C:\\\\Users\\\\hirom\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('D:\\\\NLP\\\\JParaCrawl')\n",
    "sys.path.append('C:\\\\users\\\\hirom\\\\nlp\\\\llm\\cuda\\\\lib\\\\site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5cd1d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\hirom\\\\NLP\\\\LLM\\\\fcc-gpt-course',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\python39.zip',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\DLLs',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3',\n",
      " '',\n",
      " 'C:\\\\Users\\\\hirom\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'C:\\\\Users\\\\hirom\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
      " 'D:\\\\NLP\\\\JParaCrawl',\n",
      " 'C:\\\\users\\\\hirom\\\\nlp\\\\llm\\\\cuda\\\\lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7767e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b220ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5d37b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            lines.append(line.strip())\n",
    "    return lines\n",
    "\n",
    "en_train_path = 'D:\\\\NLP\\\\JParaCrawl\\\\JP_en_train.txt'\n",
    "en_test_path = 'D:\\\\NLP\\\\JParaCrawl\\\\JP_en_test.txt'\n",
    "ja_train_path = 'D:\\\\NLP\\\\JParaCrawl\\\\JP_ja_train.txt'\n",
    "ja_test_path = 'D:\\\\NLP\\\\JParaCrawl\\\\JP_ja_test.txt'\n",
    "\n",
    "en_train = load_data(en_train_path)\n",
    "en_test = load_data(en_test_path)\n",
    "ja_train = load_data(ja_train_path)\n",
    "ja_test = load_data(ja_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ad30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts:  92%|█████████████████████████████████████████████████▉    | 364734/394379 [02:17<00:09, 2970.85it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [02:29<00:00, 2642.55it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [02:28<00:00, 2658.12it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [02:23<00:00, 2750.91it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [02:22<00:00, 2760.31it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [02:19<00:00, 2834.74it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:00<00:00, 2180.21it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:49<00:00, 1714.93it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:45<00:00, 1747.50it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:42<00:00, 1774.56it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:44<00:00, 1752.92it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:49<00:00, 1715.85it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:42<00:00, 1769.46it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:45<00:00, 1745.56it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:47<00:00, 1734.86it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:45<00:00, 1749.11it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:51<00:00, 1703.70it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:58<00:00, 1650.96it/s]\n",
      "Processing texts: 100%|███████████████████████████████████████████████████████| 394379/394379 [12:15<00:00, 536.43it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:49<00:00, 1715.77it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394394/394394 [03:57<00:00, 1658.79it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1668.55it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1729.29it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1637.47it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1680.54it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1737.33it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1693.71it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1699.08it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1641.17it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1698.26it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1685.78it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1656.03it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1694.29it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1652.13it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1713.39it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1622.91it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1725.92it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1722.51it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1661.28it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1736.41it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1715.37it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:19<00:00, 1519.69it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:19<00:00, 1522.39it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:18<00:00, 1524.57it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:40<00:00, 1405.47it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:49<00:00, 1361.47it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:41<00:00, 1401.93it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:30<00:00, 1457.96it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:33<00:00, 1441.32it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:22<00:00, 1504.91it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:18<00:00, 1524.83it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:48<00:00, 1365.71it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:24<00:00, 1488.48it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:16<00:00, 1535.86it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:21<00:00, 1507.53it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [03:40<00:00, 1790.05it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:40<00:00, 1407.09it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:49<00:00, 1362.67it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:38<00:00, 1414.17it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394379/394379 [04:16<00:00, 1537.15it/s]\n",
      "Processing texts: 100%|██████████████████████████████████████████████████████| 394394/394394 [03:59<00:00, 1644.26it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1651.68it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1604.95it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:25<00:00, 1737.18it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1662.26it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1592.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1616.32it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1597.40it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1593.08it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1626.75it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1602.63it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1604.66it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1681.13it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1614.59it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1645.25it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1654.96it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1630.52it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1623.35it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1653.86it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:26<00:00, 1672.96it/s]\n",
      "Processing texts: 100%|████████████████████████████████████████████████████████| 43820/43820 [00:27<00:00, 1598.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing time: 4h 33m 31.01s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "def encoding(text_list, tokenizer):\n",
    "    encoded_texts = []\n",
    "    for text in tqdm(text_list, desc=\"Processing texts\", leave=True):\n",
    "        encoded_text = tokenizer(text, add_special_tokens=True, padding=False, truncation=False, return_tensors='pt')\n",
    "        encoded_texts.append(encoded_text)\n",
    "    return encoded_texts\n",
    "\n",
    "\n",
    "def process_and_save_chunks(data, tokenizer, num_chunks=20, prefix='chunk', save_dir='.'):\n",
    "    \"\"\"Process data in chunks, save each chunk, and clear from memory.\"\"\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    chunk_size = len(data) // num_chunks\n",
    "    for i in range(num_chunks):\n",
    "        start_idx = i * chunk_size\n",
    "        end_idx = (i + 1) * chunk_size if i != num_chunks - 1 else len(data)\n",
    "\n",
    "        chunk = data[start_idx:end_idx]\n",
    "        encoded_chunk = encoding(chunk, tokenizer)\n",
    "\n",
    "        # Save chunk to file\n",
    "        file_path = os.path.join(save_dir, f'{prefix}_encoded_chunk_{i}.pkl')\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(encoded_chunk, f)\n",
    "\n",
    "        # Clear memory\n",
    "        del chunk\n",
    "        del encoded_chunk\n",
    "        torch.cuda.empty_cache()  # If using GPU\n",
    "\n",
    "\n",
    "save_dir = 'D:\\\\NLP\\\\JParaCrawl\\\\encoded_data'\n",
    "\n",
    "\n",
    "process_and_save_chunks(ja_train, tokenizer, num_chunks=20, prefix='ja_train', save_dir=save_dir)\n",
    "process_and_save_chunks(ja_test, tokenizer, num_chunks=20, prefix='ja_test', save_dir=save_dir)\n",
    "process_and_save_chunks(en_train, tokenizer, num_chunks=20, prefix='en_train', save_dir=save_dir)\n",
    "process_and_save_chunks(en_test, tokenizer, num_chunks=20, prefix='en_test', save_dir=save_dir)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "encoded_ja_train = encoding(ja_train, tokenizer)\n",
    "encoded_ja_test = encoding(ja_test, tokenizer)\n",
    "encoded_en_train = encoding(en_train, tokenizer)\n",
    "encoded_en_test = encoding(en_test, tokenizer)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "\n",
    "def format_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    return f\"Processing time: {hours}h {minutes}m {seconds:.2f}s\"\n",
    "\n",
    "print(format_time(processing_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
